# -*- coding: utf-8 -*-
"""content_based_filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t41GFErTWVLE-p2yJjyVX9jXNp4kprwL
"""

"""
Script 6: Content-Based Filtering (TF-IDF)
Uses movie genres/tags for content-based recommendations
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

print("\n" + "="*60)
print("CONTENT-BASED FILTERING (TF-IDF)")
print("="*60)

# Load training data
print("Loading training data...")
train_df = pd.read_csv('/content/drive/MyDrive/train_data.csv')
print(f"✓ Loaded {len(train_df):,} training records")

# Create movie metadata (genres + tags)
print("\nPreparing movie content features...")

# Combine genres and tags for each movie
movie_features = train_df.groupby('movieId').agg({
    'title': 'first',
    'genres': 'first',
    'tags': lambda x: ' '.join([str(tag) for tag in x if pd.notna(tag)])
}).reset_index()

# Create combined content string
movie_features['content'] = (
    movie_features['genres'].fillna('') + ' ' +
    movie_features['tags'].fillna('')
).str.strip()

# Remove movies with no content
movie_features = movie_features[movie_features['content'] != '']
print(f"✓ Prepared content for {len(movie_features)} movies")

print("\n" + "="*60)
print("COMPUTING TF-IDF MATRIX")
print("="*60)

# Create TF-IDF vectorizer
tfidf = TfidfVectorizer(
    stop_words='english',
    max_features=1000,
    ngram_range=(1, 2),
    min_df=2
)

# Fit and transform
print("Computing TF-IDF vectors...")
tfidf_matrix = tfidf.fit_transform(movie_features['content'])
print(f"✓ TF-IDF matrix shape: {tfidf_matrix.shape}")
print(f"  Movies: {tfidf_matrix.shape[0]}")
print(f"  Features: {tfidf_matrix.shape[1]}")

# Compute movie-movie similarity
print("\nComputing content similarity matrix...")
content_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)
print(f"✓ Similarity matrix shape: {content_similarity.shape}")

# Create movie ID to index mapping
movie_idx_map = {movie_id: idx for idx, movie_id in enumerate(movie_features['movieId'])}

print("\n" + "="*60)
print("BUILDING CONTENT-BASED MODEL")
print("="*60)

class ContentBasedFiltering:
    """Content-Based Filtering using TF-IDF"""

    def __init__(self, movie_features, content_similarity, movie_idx_map, train_df):
        self.movie_features = movie_features
        self.content_similarity = content_similarity
        self.movie_idx_map = movie_idx_map
        self.train_df = train_df
        self.global_mean = train_df['rating'].mean()

    def get_similar_movies(self, movie_id, k=10):
        """Get k most similar movies based on content"""
        if movie_id not in self.movie_idx_map:
            return []

        idx = self.movie_idx_map[movie_id]
        sim_scores = self.content_similarity[idx]

        # Get top k similar movies (excluding the movie itself)
        similar_indices = np.argsort(sim_scores)[::-1][1:k+1]
        similar_movies = [
            (self.movie_features.iloc[i]['movieId'], sim_scores[i])
            for i in similar_indices
        ]
        return similar_movies

    def predict(self, user_id, movie_id, k=20):
        """Predict rating using content-based approach"""
        if movie_id not in self.movie_idx_map:
            return self.global_mean

        # Get user's rating history
        user_ratings = self.train_df[self.train_df['userId'] == user_id]

        if len(user_ratings) == 0:
            return self.global_mean

        # Get similar movies
        similar_movies = self.get_similar_movies(movie_id, k=k)

        if len(similar_movies) == 0:
            return self.global_mean

        # Find ratings for similar movies
        ratings = []
        weights = []

        for sim_movie_id, similarity in similar_movies:
            user_movie_rating = user_ratings[user_ratings['movieId'] == sim_movie_id]
            if len(user_movie_rating) > 0:
                ratings.append(user_movie_rating['rating'].values[0])
                weights.append(similarity)

        if len(ratings) == 0 or sum(weights) == 0:
            return self.global_mean

        return np.average(ratings, weights=weights)

# Initialize model
cbf_model = ContentBasedFiltering(
    movie_features,
    content_similarity,
    movie_idx_map,
    train_df
)
print("✓ Content-based model initialized")

# Save model
print("\n" + "="*60)
print("SAVING MODEL")
print("="*60)

cbf_data = {
    'movie_features': movie_features,
    'content_similarity': content_similarity,
    'movie_idx_map': movie_idx_map,
    'tfidf': tfidf,
    'global_mean': train_df['rating'].mean()
}

with open('/content/drive/MyDrive/cbf_model.pkl', 'wb') as f:
    pickle.dump(cbf_data, f)
print("✓ Saved: cbf_model.pkl")

# Test predictions
print("\n" + "="*60)
print("TESTING CONTENT-BASED PREDICTIONS")
print("="*60)

test_user = train_df['userId'].iloc[0]
test_movie = train_df['movieId'].iloc[100]

print(f"Test User ID: {test_user}")
print(f"Test Movie ID: {test_movie}")

if test_movie in movie_idx_map:
    print(f"\nMovie: {movie_features[movie_features['movieId']==test_movie]['title'].values[0]}")
    print(f"Content: {movie_features[movie_features['movieId']==test_movie]['content'].values[0][:100]}...")

    # Get similar movies
    similar = cbf_model.get_similar_movies(test_movie, k=5)
    print(f"\nTop 5 similar movies:")
    for i, (movie_id, sim_score) in enumerate(similar, 1):
        movie_title = movie_features[movie_features['movieId']==movie_id]['title'].values[0]
        print(f"  {i}. {movie_title} (similarity: {sim_score:.3f})")

    # Prediction
    prediction = cbf_model.predict(test_user, test_movie, k=20)
    print(f"\nContent-based prediction: {prediction:.2f}")
else:
    print("Test movie not in content database")

print("\n" + "="*60)
print("CONTENT-BASED FILTERING COMPLETE!")
print("="*60)
print("Next: Run '7_neural_collaborative_filtering.py'")