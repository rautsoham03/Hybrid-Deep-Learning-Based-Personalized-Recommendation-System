# -*- coding: utf-8 -*-
"""rnn_sequential.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TXSGrdO4bAHBjJV2YLWC-83A-MR6H9gW
"""

"""
Script 8: RNN for Rating Prediction (FIXED)
Models sequential patterns to predict ratings
"""

import pandas as pd
import numpy as np
import pickle
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.sequence import pad_sequences

print("\n" + "="*60)
print("RNN FOR SEQUENTIAL RATING PREDICTION")
print("="*60)

# Load training data
print("Loading training data...")
train_df = pd.read_csv('/content/drive/MyDrive/train_data.csv')
test_df = pd.read_csv('/content/drive/MyDrive/test_data.csv')
train_df['rating_time'] = pd.to_datetime(train_df['rating_time'])
test_df['rating_time'] = pd.to_datetime(test_df['rating_time'])
train_df = train_df.sort_values(['userId', 'rating_time'])
test_df = test_df.sort_values(['userId', 'rating_time'])
print(f"✓ Loaded {len(train_df):,} train records")
print(f"✓ Loaded {len(test_df):,} test records")

# Parameters
sequence_length = 10
n_movies = train_df['movie_id_encoded'].max() + 1
n_users = train_df['user_id_encoded'].max() + 1

print(f"\nSequence length: {sequence_length}")
print(f"Number of movies: {n_movies}")
print(f"Number of users: {n_users}")

print("\n" + "="*60)
print("CREATING SEQUENTIAL DATA FOR RATING PREDICTION")
print("="*60)

def create_rating_sequences(df, seq_length):
    """Create sequences to predict next rating"""
    user_seqs = []
    movie_seqs = []
    target_movies = []
    target_ratings = []

    for user_id in df['userId'].unique():
        user_data = df[df['userId'] == user_id].sort_values('rating_time')

        if len(user_data) < 2:
            continue

        user_movies = user_data['movie_id_encoded'].values
        user_ratings = user_data['rating'].values
        user_encoded = user_data['user_id_encoded'].values[0]

        for i in range(1, len(user_movies)):
            # Input: previous movie sequence
            movie_seq = user_movies[max(0, i-seq_length):i]

            # Target: next movie and rating
            target_movie = user_movies[i]
            target_rating = user_ratings[i]

            user_seqs.append(user_encoded)
            movie_seqs.append(movie_seq)
            target_movies.append(target_movie)
            target_ratings.append(target_rating)

    return user_seqs, movie_seqs, target_movies, target_ratings

print("Creating sequences...")
user_seqs, movie_seqs, target_movies, target_ratings = create_rating_sequences(train_df, sequence_length)
print(f"✓ Created {len(user_seqs):,} sequences")

# Pad sequences
X_users = np.array(user_seqs)
X_movies = pad_sequences(movie_seqs, maxlen=sequence_length, padding='pre', value=0)
X_target_movies = np.array(target_movies)
y = np.array(target_ratings)

print(f"X_users shape: {X_users.shape}")
print(f"X_movies shape: {X_movies.shape}")
print(f"X_target_movies shape: {X_target_movies.shape}")
print(f"y shape: {y.shape}")

# Normalize ratings
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()

# Split
split_idx = int(len(X_users) * 0.9)
X_users_train = X_users[:split_idx]
X_movies_train = X_movies[:split_idx]
X_target_train = X_target_movies[:split_idx]
y_train = y_scaled[:split_idx]

X_users_val = X_users[split_idx:]
X_movies_val = X_movies[split_idx:]
X_target_val = X_target_movies[split_idx:]
y_val = y_scaled[split_idx:]

print(f"\nTraining: {len(X_users_train):,}")
print(f"Validation: {len(X_users_val):,}")

print("\n" + "="*60)
print("BUILDING RATING PREDICTION RNN")
print("="*60)

# Inputs
user_input = layers.Input(shape=(1,), name='user_input')
movie_seq_input = layers.Input(shape=(sequence_length,), name='movie_seq_input')
target_movie_input = layers.Input(shape=(1,), name='target_movie_input')

# Embeddings
user_emb = layers.Embedding(n_users, 50, name='user_embedding')(user_input)
user_emb = layers.Flatten()(user_emb)

movie_seq_emb = layers.Embedding(n_movies, 50, name='movie_seq_embedding')(movie_seq_input)
rnn_out = layers.GRU(128, return_sequences=False, name='gru')(movie_seq_emb)

target_movie_emb = layers.Embedding(n_movies, 50, name='target_movie_embedding')(target_movie_input)
target_movie_emb = layers.Flatten()(target_movie_emb)

# Concatenate all
concat = layers.Concatenate()([user_emb, rnn_out, target_movie_emb])

# Dense layers
x = layers.Dense(256, activation='relu')(concat)
x = layers.Dropout(0.3)(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.2)(x)
output = layers.Dense(1, activation='sigmoid', name='rating_output')(x)

rnn_model = keras.Model(
    inputs=[user_input, movie_seq_input, target_movie_input],
    outputs=output,
    name='RNN_Rating_Model'
)

rnn_model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

print("\n" + "="*60)
print("MODEL ARCHITECTURE")
print("="*60)
rnn_model.summary()

print("\n" + "="*60)
print("TRAINING RNN MODEL")
print("="*60)

early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

history = rnn_model.fit(
    [X_users_train, X_movies_train, X_target_train],
    y_train,
    batch_size=256,
    epochs=20,
    validation_data=([X_users_val, X_movies_val, X_target_val], y_val),
    callbacks=[early_stopping],
    verbose=1
)

print("\n✓ Training complete!")

# Save model
print("\n" + "="*60)
print("SAVING MODEL")
print("="*60)

rnn_model.save('/content/drive/MyDrive/rnn_model.h5')
with open('/content/drive/MyDrive/rnn_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
with open('/content/drive/MyDrive/rnn_params.pkl', 'wb') as f:
    pickle.dump({'sequence_length': sequence_length}, f)

print("✓ Saved: rnn_model.h5, rnn_scaler.pkl, rnn_params.pkl")
print("\n" + "="*60)
print("RNN MODEL COMPLETE!")
print("="*60)
print("Next: Run '9_model_fusion.py'")