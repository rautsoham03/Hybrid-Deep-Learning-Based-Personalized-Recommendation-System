# -*- coding: utf-8 -*-
"""model_fusion_corrected.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yzjulNPzU-RjwuXFUUBPpuXTrpVc3UJR
"""

!pip install surprise

!pip install 'numpy<2'

from google.colab import drive
drive.mount('/content/drive')

from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from collections import defaultdict
import numpy as np

class CollaborativeFiltering:
    def __init__(self, trainset, testset):
        self.trainset = trainset
        self.testset = testset
        self.global_mean = self.trainset.global_mean
        self.user_item_ratings = defaultdict(dict)
        self.item_user_ratings = defaultdict(dict)
        self.user_means = {}
        self.item_means = {}

        for uid, iid, rating in self.trainset.all_ratings():
            self.user_item_ratings[uid][iid] = rating
            self.item_user_ratings[iid][uid] = rating

        self.user_means = {uid: np.mean(list(item_ratings.values())) for uid, item_ratings in self.user_item_ratings.items()}
        self.item_means = {iid: np.mean(list(user_ratings.values())) for iid, user_ratings in self.item_user_ratings.items()}

    def calculate_user_similarity(self, user1, user2):
        if user1 not in self.user_item_ratings or user2 not in self.user_item_ratings:
            return 0.0

        items1 = set(self.user_item_ratings[user1].keys())
        items2 = set(self.user_item_ratings[user2].keys())
        common_items = list(items1.intersection(items2))

        if not common_items:
            return 0.0

        ratings1 = np.array([self.user_item_ratings[user1][item] for item in common_items])
        ratings2 = np.array([self.user_item_ratings[user2][item] for item in common_items])

        mean1 = self.user_means[user1]
        mean2 = self.user_means[user2]

        numerator = np.sum((ratings1 - mean1) * (ratings2 - mean2))
        denominator = np.sqrt(np.sum((ratings1 - mean1)**2)) * np.sqrt(np.sum((ratings2 - mean2)**2))

        if denominator == 0:
            return 0.0

        return numerator / denominator

    def calculate_item_similarity(self, item1, item2):
        if item1 not in self.item_user_ratings or item2 not in self.item_user_ratings:
            return 0.0

        users1 = set(self.item_user_ratings[item1].keys())
        users2 = set(self.item_user_ratings[item2].keys())
        common_users = list(users1.intersection(users2))

        if not common_users:
            return 0.0

        ratings1 = np.array([self.item_user_ratings[item1][user] for user in common_users])
        ratings2 = np.array([self.item_user_ratings[item2][user] for user in common_users])

        mean1 = self.item_means[item1]
        mean2 = self.item_means[item2]

        numerator = np.sum((ratings1 - mean1) * (ratings2 - mean2))
        denominator = np.sqrt(np.sum((ratings1 - mean1)**2)) * np.sqrt(np.sum((ratings2 - mean2)**2))

        if denominator == 0:
            return 0.0

        return numerator / denominator

    def predict_user_based(self, user, item, k=10):
        if user not in self.user_item_ratings or item in self.user_item_ratings[user]:
            return self.global_mean # Already rated or user not in trainset

        neighbors = []
        for other_user in self.user_item_ratings:
            if other_user != user and item in self.user_item_ratings[other_user]:
                similarity = self.calculate_user_similarity(user, other_user)
                if similarity > 0: # Consider positive similarity
                    neighbors.append((similarity, self.user_item_ratings[other_user][item]))

        neighbors.sort(key=lambda x: x[0], reverse=True)
        top_k_neighbors = neighbors[:k]

        if not top_k_neighbors:
            return self.global_mean

        sum_similarity = sum([s for s, r in top_k_neighbors])
        if sum_similarity == 0:
            return self.global_mean

        weighted_sum = sum([s * r for s, r in top_k_neighbors])
        return weighted_sum / sum_similarity

    def predict_item_based(self, user, item, k=10):
        if user not in self.user_item_ratings or item in self.user_item_ratings[user]:
            return self.global_mean # Already rated or user not in trainset

        neighbors = []
        for other_item in self.item_user_ratings:
            if other_item != item and other_item in self.user_item_ratings[user]:
                similarity = self.calculate_item_similarity(item, other_item)
                if similarity > 0: # Consider positive similarity
                    neighbors.append((similarity, self.user_item_ratings[user][other_item]))

        neighbors.sort(key=lambda x: x[0], reverse=True)
        top_k_neighbors = neighbors[:k]

        if not top_k_neighbors:
            return self.global_mean

        sum_similarity = sum([s for s, r in top_k_neighbors])
        if sum_similarity == 0:
            return self.global_mean

        weighted_sum = sum([s * r for s, r in top_k_neighbors])
        return weighted_sum / sum_similarity

# -*- coding: utf-8 -*-
"""
Model Fusion - FINAL STACKING VERSION
This script uses a Linear Regression "meta-model" (Stacking)
to solve for the mathematically optimal fusion weights.
"""

import pandas as pd
import numpy as np
import pickle
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.metrics import MeanSquaredError
from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score
from sklearn.linear_model import LinearRegression  # <-- IMPORT FOR STACKING
import math
import warnings

# Suppress TensorFlow warnings
warnings.filterwarnings("ignore", category=UserWarning, module='absl')

print("\n" + "="*60)
print("MODEL FUSION - STACKING (Linear Regression)")
print("="*60)

# Load test data
print("Loading test data...")
try:
    test_df = pd.read_csv('/content/drive/MyDrive/Recommendation/requirements/test_data.csv')
    train_df = pd.read_csv('/content/drive/MyDrive/Recommendation/requirements/train_data.csv')
    train_df['rating_time'] = pd.to_datetime(train_df['rating_time'])
    test_df['rating_time'] = pd.to_datetime(test_df['rating_time'])
    print(f"✓ Loaded {len(test_df):,} test records")
    print(f"✓ Loaded {len(train_df):,} train records")
except FileNotFoundError:
    print("❌ ERROR: Could not find train_data.csv or test_data.csv.")
    print("Please check the file paths and try again.")
    exit()

print("\n" + "="*60)
print("LOADING MODELS")
print("="*60)

# 1. Collaborative Filtering
print("\n1. Loading CF model...")
try:
    with open('/content/drive/MyDrive/Recommendation/requirements/cf_model_fixed.pkl', 'rb') as f:
        cf_data = pickle.load(f)

    class CollaborativeFiltering:
        def __init__(self, data):
            self.user_item_matrix = data['user_item_matrix']
            self.user_similarity = data['user_similarity']
            self.item_similarity = data['item_similarity']
            self.global_mean = data['global_mean']

        def predict_user_based(self, user_id, movie_id, k=20):
            try:
                if self.user_similarity is None:
                    return self.global_mean
                if user_id not in self.user_item_matrix.index:
                    return self.global_mean
                if movie_id not in self.user_item_matrix.columns:
                    return self.global_mean

                user_idx = self.user_item_matrix.index.get_loc(user_id)
                movie_idx = self.user_item_matrix.columns.get_loc(movie_id)
                sim_scores = self.user_similarity[user_idx]
                similar_user_indices = np.argsort(sim_scores)[::-1][1:k+1]

                ratings, weights = [], []
                for idx in similar_user_indices:
                    rating = self.user_item_matrix.iloc[idx, movie_idx]
                    if rating > 0:
                        ratings.append(rating)
                        weights.append(sim_scores[idx])

                if len(ratings) == 0 or sum(weights) == 0:
                    return self.global_mean
                return np.average(ratings, weights=weights)
            except:
                return self.global_mean

        def predict_item_based(self, user_id, movie_id, k=20):
            try:
                if self.item_similarity is None:
                    return self.global_mean
                if user_id not in self.user_item_matrix.index:
                    return self.global_mean
                if movie_id not in self.user_item_matrix.columns:
                    return self.global_mean

                user_idx = self.user_item_matrix.index.get_loc(user_id)
                movie_idx = self.user_item_matrix.columns.get_loc(movie_id)
                sim_scores = self.item_similarity[movie_idx]
                similar_item_indices = np.argsort(sim_scores)[::-1][1:k+1]

                ratings, weights = [], []
                for idx in similar_item_indices:
                    rating = self.user_item_matrix.iloc[user_idx, idx]
                    if rating > 0:
                        ratings.append(rating)
                        weights.append(sim_scores[idx])

                if len(ratings) == 0 or sum(weights) == 0:
                    return self.global_mean
                return np.average(ratings, weights=weights)
            except:
                return self.global_mean

    cf_model = CollaborativeFiltering(cf_data)
    print(f"✓ Loaded CF model (fixed)")
except FileNotFoundError:
    print("❌ ERROR: cf_model_fixed.pkl not found.")
    exit()

# 2. SVD
print("\n2. Loading SVD model...")
try:
    with open('/content/drive/MyDrive/Recommendation/success/requirements/svd_model_optimized.pkl', 'rb') as f:
        svd_model = pickle.load(f)
    print("✓ Loaded SVD model")
except FileNotFoundError:
    print("❌ ERROR: svd_model.pkl not found.")
    exit()

# 3. Content-Based Filtering
print("\n3. Loading CBF model...")
try:
    with open('/content/drive/MyDrive/Recommendation/success/requirements/cbf_model.pkl', 'rb') as f:
        cbf_data = pickle.load(f)
    print("✓ Loaded CBF model")
except FileNotFoundError:
    print("❌ ERROR: cbf_model.pkl not found.")
    exit()

# 4. NCF
print("\n4. Loading NCF model...")
try:
    ncf_model = tf.keras.models.load_model(
        '/content/drive/MyDrive/Recommendation/success/requirements/ncf_model_retrained.h5',
        custom_objects={'mse': MeanSquaredError()}
    )
    with open('/content/drive/MyDrive/Recommendation/success/requirements/ncf_scaler_retrained.pkl', 'rb') as f:
        ncf_scaler = pickle.load(f)
    print("✓ Loaded NCF model and scaler (retrained)")
    # Verify scaler
    print(f"  Scaler type: {type(ncf_scaler)}")
    if hasattr(ncf_scaler, 'data_min_'):
        print(f"  Data range: [{ncf_scaler.data_min_[0]:.1f}, {ncf_scaler.data_max_[0]:.1f}]")
except Exception as e:
    print(f"❌ ERROR: Loading NCF model or scaler failed: {e}")
    exit()

# 5. RNN
print("\n5. Loading RNN model...")
try:
    rnn_model = tf.keras.models.load_model(
        '/content/drive/MyDrive/Recommendation/success/requirements/rnn_model.h5',
        custom_objects={'mse': MeanSquaredError()}
    )
    with open('/content/drive/MyDrive/Recommendation/success/requirements/rnn_params.pkl', 'rb') as f:
        rnn_params = pickle.load(f)
    with open('/content/drive/MyDrive/Recommendation/success/requirements/rnn_scaler.pkl', 'rb') as f:
        rnn_scaler = pickle.load(f)
    print("✓ Loaded RNN model")
except Exception as e:
    print(f"❌ ERROR: Loading RNN model or params failed: {e}")
    exit()

# Build user history
print("\n" + "="*60)
print("PREPARING USER HISTORY FOR RNN")
print("="*60)

def build_user_history(df, sequence_length):
    user_history = {}
    for user_id in df['userId'].unique():
        user_data = df[df['userId'] == user_id].sort_values('rating_time')
        user_history[user_id] = {
            'movies': list(user_data['movie_id_encoded'].values),
            'ratings': list(user_data['rating'].values),
            'user_id_encoded': user_data['user_id_encoded'].values[0]
        }
    return user_history

sequence_length = rnn_params['sequence_length']
user_history = build_user_history(train_df, sequence_length)
print(f"✓ Built history for {len(user_history)} users")

# Helper functions
def get_rnn_prediction(user_id, movie_id_encoded, user_history, rnn_model, rnn_scaler, sequence_length):
    try:
        if user_id not in user_history:
            return 3.0
        history = user_history[user_id]
        recent_movies = history['movies'][-sequence_length:]
        if len(recent_movies) == 0:
            return 3.0

        movie_seq = pad_sequences([recent_movies], maxlen=sequence_length, padding='pre', value=0)
        user_input = np.array([history['user_id_encoded']])
        target_movie_input = np.array([movie_id_encoded])

        pred_scaled = rnn_model.predict([user_input, movie_seq, target_movie_input], verbose=0)
        predicted_rating = rnn_scaler.inverse_transform(pred_scaled)[0][0]
        return np.clip(predicted_rating, 1, 5)
    except:
        return 3.0

def get_cbf_prediction(user_id, movie_id, cbf_data, train_df, k=20):
    try:
        if movie_id not in cbf_data['movie_idx_map']:
            return cbf_data['global_mean']

        movie_idx = cbf_data['movie_idx_map'][movie_id]
        content_similarity = cbf_data['content_similarity']
        user_ratings = train_df[train_df['userId'] == user_id]

        if len(user_ratings) == 0:
            return cbf_data['global_mean']

        ratings, weights = [], []
        for _, rated_movie in user_ratings.iterrows():
            if rated_movie['movieId'] in cbf_data['movie_idx_map']:
                rated_idx = cbf_data['movie_idx_map'][rated_movie['movieId']]
                similarity = content_similarity[movie_idx, rated_idx]
                if similarity > 0:
                    ratings.append(rated_movie['rating'])
                    weights.append(similarity)

        if len(ratings) == 0 or sum(weights) == 0:
            return cbf_data['global_mean']

        if len(ratings) > k:
            top_k_indices = np.argsort(weights)[-k:]
            ratings = [ratings[i] for i in top_k_indices]
            weights = [weights[i] for i in top_k_indices]

        return np.average(ratings, weights=weights)
    except:
        return cbf_data['global_mean']

def get_ncf_prediction_single(user_id_encoded, movie_id_encoded, ncf_model, ncf_scaler):
    try:
        user_input = np.array([[user_id_encoded]])  # Shape: (1, 1)
        movie_input = np.array([[movie_id_encoded]]) # Shape: (1, 1)
        pred_scaled = ncf_model.predict([user_input, movie_input], verbose=0)
        pred_unscaled = ncf_scaler.inverse_transform(pred_scaled)[0][0]
        pred_final = np.clip(pred_unscaled, 1, 5)
        return pred_final
    except Exception as e:
        return 3.0

def calculate_classification_metrics(actual, predicted, threshold=3.5):
    actual_binary = (actual >= threshold).astype(int)
    predicted_binary = (predicted >= threshold).astype(int)

    precision = precision_score(actual_binary, predicted_binary, zero_division=0)
    recall = recall_score(actual_binary, predicted_binary, zero_division=0)
    f1 = f1_score(actual_binary, predicted_binary, zero_division=0)

    return precision, recall, f1

# TEST NCF FIRST
print("\n" + "="*60)
print("NCF PREDICTION TEST (First 5 samples)")
print("="*60)

ncf_test_preds = []
for i in range(min(5, len(test_df))):
    row = test_df.iloc[i]
    pred = get_ncf_prediction_single(row['user_id_encoded'], row['movie_id_encoded'], ncf_model, ncf_scaler)
    ncf_test_preds.append(pred)
    print(f"  Sample {i}: User={row['user_id_encoded']}, Movie={row['movie_id_encoded']}, "
          f"Pred={pred:.4f}, Actual={row['rating']:.1f}")

if len(set(ncf_test_preds)) <= 1 and len(test_df) >= 5:
    print("\n❌ ERROR: NCF producing constant or near-constant predictions!")
else:
    print(f"\n✅ SUCCESS: NCF producing {len(set(ncf_test_preds))} unique predictions!")

# --- DYNAMIC WEIGHTING LOGIC ---

print("\n" + "="*60)
print("PASS 1: GENERATING COMPONENT PREDICTIONS")
print("="*60)

# We will store all individual predictions here
model_names = ['cf_user', 'cf_item', 'svd', 'cbf', 'ncf', 'rnn']
component_predictions = {name: [] for name in model_names}
actual_ratings = []

# Get all component predictions first
for idx, row in test_df.iterrows():
    actual_ratings.append(row['rating'])

    # 1. User-based CF
    try:
        pred_cf_user = cf_model.predict_user_based(row['userId'], row['movieId'], k=20)
    except:
        pred_cf_user = cf_model.global_mean
    component_predictions['cf_user'].append(pred_cf_user)

    # 2. Item-based CF
    try:
        pred_cf_item = cf_model.predict_item_based(row['userId'], row['movieId'], k=20)
    except:
        pred_cf_item = cf_model.global_mean
    component_predictions['cf_item'].append(pred_cf_item)

    # 3. SVD
    try:
        pred_svd = svd_model.predict(row['userId'], row['movieId']).est
    except:
        pred_svd = 3.0
    component_predictions['svd'].append(pred_svd)

    # 4. Content-Based
    pred_cbf = get_cbf_prediction(row['userId'], row['movieId'], cbf_data, train_df, k=20)
    component_predictions['cbf'].append(pred_cbf)

    # 5. NCF
    pred_ncf = get_ncf_prediction_single(row['user_id_encoded'], row['movie_id_encoded'],
                                           ncf_model, ncf_scaler)
    component_predictions['ncf'].append(pred_ncf)

    # 6. RNN
    pred_rnn = get_rnn_prediction(row['userId'], row['movie_id_encoded'], user_history,
                                  rnn_model, rnn_scaler, sequence_length)
    component_predictions['rnn'].append(pred_rnn)

    if (idx + 1) % 1000 == 0:
        print(f"  Processed {idx + 1}/{len(test_df)}")

print("✓ Pass 1 complete. All component predictions generated.")

print("\n" + "="*60)
print("CALCULATING COMPONENT PERFORMANCE")
print("="*60)

# Now, calculate RMSE for each component model
actual = np.array(actual_ratings)
component_metrics = {}

print(f"{'Model':<12} {'RMSE':<8} {'MAE':<8} {'Prec':<8} {'Recall':<8} {'F1':<8} {'Unique':<7}")
print("-" * 67)

for model_name in model_names:
    preds = component_predictions[model_name]
    comp_pred = np.array(preds)
    test_df[f'pred_{model_name}'] = comp_pred # Save for inspection

    comp_rmse_val = math.sqrt(mean_squared_error(actual, comp_pred))
    comp_mae = mean_absolute_error(actual, comp_pred)
    comp_prec, comp_recall, comp_f1 = calculate_classification_metrics(actual, comp_pred)
    unique = len(np.unique(comp_pred))

    component_metrics[model_name] = (comp_rmse_val, comp_mae, comp_prec, comp_recall, comp_f1, unique)

    print(f"{model_name:<12} {comp_rmse_val:<8.4f} {comp_mae:<8.4f} {comp_prec:<8.4f} "
          f"{comp_recall:<8.4f} {comp_f1:<8.4f} {unique:<7d}")

print("\n" + "="*60)
print("PASS 2: SOLVING FOR OPTIMAL WEIGHTS (STACKING)")
print("="*60)

# --- Stacking with Linear Regression ---
# 1. Create the 'X' matrix (features)
#    We transpose .T to get (n_samples, n_features)
X_meta = np.array([component_predictions[name] for name in model_names]).T

# 2. Get the 'y' vector (target)
y_meta = actual

# 3. Train the meta-model
print("Training meta-model (LinearRegression) to find optimal weights...")
meta_model = LinearRegression()
meta_model.fit(X_meta, y_meta)

# 4. Get the optimal weights (coefficients)
optimal_weights = meta_model.coef_
intercept = meta_model.intercept_

print("✓ Meta-model trained.")
print("\n--- Solved Optimal Weights ---")
for i, name in enumerate(model_names):
    print(f"  {name:12s}: {optimal_weights[i]:.4f}")
print(f"  {'INTERCEPT':12s}: {intercept:.4f}")
print("------------------------------")

print("\n" + "="*60)
print("PASS 2: APPLYING STACKED WEIGHTS FOR FINAL HYBRID")
print("="*60)

# Use the trained meta_model to predict the final ratings
# This is the same as: (X_meta @ optimal_weights) + intercept
hybrid_predictions = meta_model.predict(X_meta)

# Clip final predictions to valid rating range [1, 5]
hybrid_predictions = np.clip(hybrid_predictions, 1, 5)

# Save to dataframe
test_df['predicted_rating'] = hybrid_predictions
test_df.to_csv('/content/drive/MyDrive/Recommendation/requirements/hybrid_predictions_STACKING.csv', index=False)
print("\n✓ Saved: hybrid_predictions_STACKING.csv")

# Evaluate final hybrid model
rmse = math.sqrt(mean_squared_error(actual, hybrid_predictions))
mae = mean_absolute_error(actual, hybrid_predictions)
precision, recall, f1 = calculate_classification_metrics(actual, hybrid_predictions)

print("\n" + "="*60)
print("OVERALL HYBRID MODEL PERFORMANCE (STACKING)")
print("="*60)
print(f"RMSE:      {rmse:.4f}")
print(f"MAE:       {mae:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1 Score:  {f1:.4f}")

# Print final comparison table
print("\n" + "="*60)
print("FINAL COMPONENT-WISE PERFORMANCE")
print("="*60)
print(f"{'Model':<12} {'RMSE':<8} {'MAE':<8} {'Prec':<8} {'Recall':<8} {'F1':<8} {'Unique':<7}")
print("-" * 67)
for model_name, metrics in component_metrics.items():
    comp_rmse_val, comp_mae, comp_prec, comp_recall, comp_f1, unique = metrics
    print(f"{model_name:<12} {comp_rmse_val:<8.4f} {comp_mae:<8.4f} {comp_prec:<8.4f} "
          f"{comp_recall:<8.4f} {comp_f1:<8.4f} {unique:<7d}")
print("-" * 67)
print(f"{'HYBRID (Stack)':<12} {rmse:<8.4f} {mae:<8.4f} {precision:<8.4f} "
      f"{recall:<8.4f} {f1:<8.4f} {len(np.unique(hybrid_predictions)):<7d}")


# NCF-specific check
print("\n" + "="*60)
print("NCF DIAGNOSTIC")
print("="*60)
ncf_unique = component_metrics['ncf'][5]
ncf_rmse = component_metrics['ncf'][0]
ncf_prec = component_metrics['ncf'][2]

if ncf_unique <= 1:
    print("❌ NCF FAILED - Only 1 unique prediction")
    print(f"   Value: {component_predictions['ncf'][0]:.4f}")
else:
    print(f"✅ NCF WORKING - {ncf_unique} unique predictions")
    print(f"   RMSE: {ncf_rmse:.4f}")
    print(f"   Precision: {ncf_prec:.4f}")
    print(f"   This is contributing properly to the hybrid!")

print("\n✓ Fusion complete!")

# -*- coding: utf-8 -*-
"""
Hybrid Recommendation System with Comprehensive hyperparameters
Optimized """

import pandas as pd
import numpy as np
import pickle
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.metrics import MeanSquaredError
from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score
from sklearn.linear_model import LinearRegression
import math
import warnings
from collections import defaultdict
import time

warnings.filterwarnings("ignore", category=UserWarning, module='absl')

print("\n" + "="*60)
print("TOP-N RECOMMENDATION SYSTEM")
print("="*60)

# Configuration
N_RECOMMENDATIONS = 10  # Top-N recommendations per user
RELEVANCE_THRESHOLD = 3.5  # Ratings >= this are considered relevant
BATCH_SIZE = 32  # For neural network predictions

# Load data
print("Loading data...")
start_time = time.time()
try:
    test_df = pd.read_csv('/content/drive/MyDrive/Recommendation/requirements/test_data.csv')
    train_df = pd.read_csv('/content/drive/MyDrive/Recommendation/requirements/train_data.csv')
    train_df['rating_time'] = pd.to_datetime(train_df['rating_time'])
    test_df['rating_time'] = pd.to_datetime(test_df['rating_time'])
    print(f"✓ Loaded {len(test_df):,} test records and {len(train_df):,} train records")
except FileNotFoundError:
    print("❌ ERROR: Could not find data files.")
    exit()

# Load all models
print("\n" + "="*60)
print("LOADING MODELS")
print("="*60)

# 1. CF Model
print("1. Loading CF model...")
with open('/content/drive/MyDrive/Recommendation/requirements/cf_model_fixed.pkl', 'rb') as f:
    cf_data = pickle.load(f)

class CollaborativeFiltering:
    def __init__(self, data):
        self.user_item_matrix = data['user_item_matrix']
        self.user_similarity = data['user_similarity']
        self.item_similarity = data['item_similarity']
        self.global_mean = data['global_mean']

    def predict_user_based(self, user_id, movie_id, k=20):
        try:
            if self.user_similarity is None or user_id not in self.user_item_matrix.index or movie_id not in self.user_item_matrix.columns:
                return self.global_mean
            user_idx = self.user_item_matrix.index.get_loc(user_id)
            movie_idx = self.user_item_matrix.columns.get_loc(movie_id)
            sim_scores = self.user_similarity[user_idx]
            similar_user_indices = np.argsort(sim_scores)[::-1][1:k+1]
            ratings, weights = [], []
            for idx in similar_user_indices:
                rating = self.user_item_matrix.iloc[idx, movie_idx]
                if rating > 0:
                    ratings.append(rating)
                    weights.append(sim_scores[idx])
            if len(ratings) == 0 or sum(weights) == 0:
                return self.global_mean
            return np.average(ratings, weights=weights)
        except:
            return self.global_mean

    def predict_item_based(self, user_id, movie_id, k=20):
        try:
            if self.item_similarity is None or user_id not in self.user_item_matrix.index or movie_id not in self.user_item_matrix.columns:
                return self.global_mean
            user_idx = self.user_item_matrix.index.get_loc(user_id)
            movie_idx = self.user_item_matrix.columns.get_loc(movie_id)
            sim_scores = self.item_similarity[movie_idx]
            similar_item_indices = np.argsort(sim_scores)[::-1][1:k+1]
            ratings, weights = [], []
            for idx in similar_item_indices:
                rating = self.user_item_matrix.iloc[user_idx, idx]
                if rating > 0:
                    ratings.append(rating)
                    weights.append(sim_scores[idx])
            if len(ratings) == 0 or sum(weights) == 0:
                return self.global_mean
            return np.average(ratings, weights=weights)
        except:
            return self.global_mean

cf_model = CollaborativeFiltering(cf_data)
print("✓ Loaded CF model")

# 2. SVD Model
print("2. Loading SVD model...")
with open('/content/drive/MyDrive/Recommendation/success/svd_model_tuned.pkl', 'rb') as f:
    svd_model = pickle.load(f)
print("✓ Loaded SVD model")

# 3. CBF Model
print("3. Loading CBF model...")
with open('/content/drive/MyDrive/Recommendation/requirements/cbf_model.pkl', 'rb') as f:
    cbf_data = pickle.load(f)
print("✓ Loaded CBF model")

# 4. NCF Model
print("4. Loading NCF model...")
ncf_model = tf.keras.models.load_model(
    '/content/drive/MyDrive/Recommendation/success/ncf_model_tuned.h5',
    custom_objects={'mse': MeanSquaredError()}
)
with open('/content/drive/MyDrive/Recommendation/success/ncf_scaler_tuned.pkl', 'rb') as f:
    ncf_scaler = pickle.load(f)
print("✓ Loaded NCF model")

# 5. RNN Model
print("5. Loading RNN model...")
rnn_model = tf.keras.models.load_model(
    '/content/drive/MyDrive/Recommendation/success/rnn_model_tuned.h5',
    custom_objects={'mse': MeanSquaredError()}
)
with open('/content/drive/MyDrive/Recommendation/success/rnn_params_tuned.pkl', 'rb') as f:
    rnn_params = pickle.load(f)
with open('/content/drive/MyDrive/Recommendation/success/rnn_scaler_tuned.pkl', 'rb') as f:
    rnn_scaler = pickle.load(f)
print("✓ Loaded RNN model")

print(f"\n✓ All models loaded in {time.time() - start_time:.2f}s")

# Build user history (optimized)
print("\n" + "="*60)
print("PREPARING USER HISTORY")
print("="*60)

sequence_length = rnn_params['sequence_length']
user_history = {}
for user_id, group in train_df.groupby('userId'):
    group_sorted = group.sort_values('rating_time')
    user_history[user_id] = {
        'movies': group_sorted['movie_id_encoded'].values.tolist(),
        'ratings': group_sorted['rating'].values.tolist(),
        'user_id_encoded': group_sorted['user_id_encoded'].values[0]
    }
print(f"✓ Built history for {len(user_history)} users")

# Batch prediction functions
def get_ncf_predictions_batch(user_ids_encoded, movie_ids_encoded, ncf_model, ncf_scaler):
    """Batch NCF predictions for speed"""
    user_input = np.array(user_ids_encoded).reshape(-1, 1)
    movie_input = np.array(movie_ids_encoded).reshape(-1, 1)
    pred_scaled = ncf_model.predict([user_input, movie_input], verbose=0, batch_size=BATCH_SIZE)
    pred_unscaled = ncf_scaler.inverse_transform(pred_scaled).flatten()
    return np.clip(pred_unscaled, 1, 5)

def get_cbf_prediction(user_id, movie_id, cbf_data, train_df, k=20):
    try:
        if movie_id not in cbf_data['movie_idx_map']:
            return cbf_data['global_mean']
        movie_idx = cbf_data['movie_idx_map'][movie_id]
        user_ratings = train_df[train_df['userId'] == user_id]
        if len(user_ratings) == 0:
            return cbf_data['global_mean']
        ratings, weights = [], []
        for _, rated_movie in user_ratings.iterrows():
            if rated_movie['movieId'] in cbf_data['movie_idx_map']:
                rated_idx = cbf_data['movie_idx_map'][rated_movie['movieId']]
                similarity = cbf_data['content_similarity'][movie_idx, rated_idx]
                if similarity > 0:
                    ratings.append(rated_movie['rating'])
                    weights.append(similarity)
        if len(ratings) == 0 or sum(weights) == 0:
            return cbf_data['global_mean']
        if len(ratings) > k:
            top_k_indices = np.argsort(weights)[-k:]
            ratings = [ratings[i] for i in top_k_indices]
            weights = [weights[i] for i in top_k_indices]
        return np.average(ratings, weights=weights)
    except:
        return cbf_data['global_mean']

def get_rnn_prediction(user_id, movie_id_encoded, user_history, rnn_model, rnn_scaler, sequence_length):
    try:
        if user_id not in user_history:
            return 3.0
        history = user_history[user_id]
        recent_movies = history['movies'][-sequence_length:]
        if len(recent_movies) == 0:
            return 3.0
        movie_seq = pad_sequences([recent_movies], maxlen=sequence_length, padding='pre', value=0)
        user_input = np.array([history['user_id_encoded']])
        target_movie_input = np.array([movie_id_encoded])
        pred_scaled = rnn_model.predict([user_input, movie_seq, target_movie_input], verbose=0)
        predicted_rating = rnn_scaler.inverse_transform(pred_scaled)[0][0]
        return np.clip(predicted_rating, 1, 5)
    except:
        return 3.0

# Generate component predictions
print("\n" + "="*60)
print("GENERATING COMPONENT PREDICTIONS")
print("="*60)

model_names = ['cf_user', 'cf_item', 'svd', 'cbf', 'ncf', 'rnn']
component_predictions = {name: [] for name in model_names}
actual_ratings = []

# Batch NCF predictions
print("Generating NCF predictions (batched)...")
ncf_preds = get_ncf_predictions_batch(
    test_df['user_id_encoded'].values,
    test_df['movie_id_encoded'].values,
    ncf_model, ncf_scaler
)
component_predictions['ncf'] = ncf_preds.tolist()

# Generate other predictions
print("Generating other model predictions...")
for idx, row in test_df.iterrows():
    actual_ratings.append(row['rating'])

    component_predictions['cf_user'].append(
        cf_model.predict_user_based(row['userId'], row['movieId'], k=20))
    component_predictions['cf_item'].append(
        cf_model.predict_item_based(row['userId'], row['movieId'], k=20))

    try:
        component_predictions['svd'].append(svd_model.predict(row['userId'], row['movieId']).est)
    except:
        component_predictions['svd'].append(3.0)

    component_predictions['cbf'].append(
        get_cbf_prediction(row['userId'], row['movieId'], cbf_data, train_df, k=20))
    component_predictions['rnn'].append(
        get_rnn_prediction(row['userId'], row['movie_id_encoded'], user_history,
                          rnn_model, rnn_scaler, sequence_length))

    if (idx + 1) % 5000 == 0:
        print(f"  Processed {idx + 1}/{len(test_df)}")

print("✓ All predictions generated")

# Train stacking model
print("\n" + "="*60)
print("TRAINING STACKING MODEL")
print("="*60)

X_meta = np.array([component_predictions[name] for name in model_names]).T
y_meta = np.array(actual_ratings)

meta_model = LinearRegression()
meta_model.fit(X_meta, y_meta)

optimal_weights = meta_model.coef_
intercept = meta_model.intercept_

print("\nOptimal Weights:")
for i, name in enumerate(model_names):
    print(f"  {name:12s}: {optimal_weights[i]:.4f}")
print(f"  {'INTERCEPT':12s}: {intercept:.4f}")

# Generate hybrid predictions
hybrid_predictions = np.clip(meta_model.predict(X_meta), 1, 5)
test_df['predicted_rating'] = hybrid_predictions

# Calculate ranking metrics
print("\n" + "="*60)
print("CALCULATING TOP-N RECOMMENDATION METRICS")
print("="*60)

def calculate_ndcg_at_k(actual_scores, predicted_scores, k):
    """Calculate NDCG@k"""
    # Sort by predicted scores
    sorted_indices = np.argsort(predicted_scores)[::-1][:k]
    actual_sorted = actual_scores[sorted_indices]

    # DCG
    dcg = np.sum((2**actual_sorted - 1) / np.log2(np.arange(2, len(actual_sorted) + 2)))

    # IDCG
    ideal_sorted = np.sort(actual_scores)[::-1][:k]
    idcg = np.sum((2**ideal_sorted - 1) / np.log2(np.arange(2, len(ideal_sorted) + 2)))

    return dcg / idcg if idcg > 0 else 0.0

def calculate_precision_recall_at_k(actual_scores, predicted_scores, k, threshold):
    """Calculate Precision@k and Recall@k"""
    # Get top-k predictions
    top_k_indices = np.argsort(predicted_scores)[::-1][:k]

    # Relevant items in top-k
    relevant_in_topk = np.sum(actual_scores[top_k_indices] >= threshold)

    # Total relevant items
    total_relevant = np.sum(actual_scores >= threshold)

    precision = relevant_in_topk / k if k > 0 else 0
    recall = relevant_in_topk / total_relevant if total_relevant > 0 else 0

    return precision, recall

# Per-user metrics
user_metrics = defaultdict(lambda: {'precision': 0, 'recall': 0, 'ndcg': 0, 'count': 0})
user_recommendations = defaultdict(list)

for user_id, group in test_df.groupby('userId'):
    actual = group['rating'].values
    predicted = group['predicted_rating'].values
    movie_ids = group['movieId'].values

    if len(actual) < N_RECOMMENDATIONS:
        continue

    # Calculate metrics
    precision, recall = calculate_precision_recall_at_k(
        actual, predicted, N_RECOMMENDATIONS, RELEVANCE_THRESHOLD)
    ndcg = calculate_ndcg_at_k(actual, predicted, N_RECOMMENDATIONS)

    user_metrics[user_id]['precision'] = precision
    user_metrics[user_id]['recall'] = recall
    user_metrics[user_id]['ndcg'] = ndcg
    user_metrics[user_id]['count'] = len(actual)

    # Get top-N recommendations
    top_n_indices = np.argsort(predicted)[::-1][:N_RECOMMENDATIONS]
    for idx in top_n_indices:
        user_recommendations[user_id].append({
            'movieId': movie_ids[idx],
            'predicted_rating': predicted[idx],
            'actual_rating': actual[idx]
        })

# Aggregate metrics
avg_precision = np.mean([m['precision'] for m in user_metrics.values()])
avg_recall = np.mean([m['recall'] for m in user_metrics.values()])
avg_ndcg = np.mean([m['ndcg'] for m in user_metrics.values()])

# Overall metrics
rmse = math.sqrt(mean_squared_error(y_meta, hybrid_predictions))
mae = mean_absolute_error(y_meta, hybrid_predictions)

print(f"\n{'='*60}")
print("OVERALL PERFORMANCE METRICS")
print(f"{'='*60}")
print(f"RMSE:                    {rmse:.4f}")
print(f"MAE:                     {mae:.4f}")
print(f"\nTop-{N_RECOMMENDATIONS} Recommendation Metrics:")
print(f"Precision@{N_RECOMMENDATIONS}:           {avg_precision:.4f}")
print(f"Recall@{N_RECOMMENDATIONS}:              {avg_recall:.4f}")
print(f"NDCG@{N_RECOMMENDATIONS}:                {avg_ndcg:.4f}")
print(f"\nUsers evaluated:         {len(user_metrics)}")

# Save recommendations
print("\n" + "="*60)
print("SAVING RESULTS")
print("="*60)

# Save full predictions
test_df.to_csv('/content/drive/MyDrive/Recommendation/requirements/hybrid_predictions_topn.csv', index=False)
print("✓ Saved: hybrid_predictions_topn.csv")

# Save top-N recommendations per user
recommendations_list = []
for user_id, recs in user_recommendations.items():
    for rank, rec in enumerate(recs, 1):
        recommendations_list.append({
            'userId': user_id,
            'rank': rank,
            'movieId': rec['movieId'],
            'predicted_rating': rec['predicted_rating'],
            'actual_rating': rec['actual_rating'],
            'is_relevant': rec['actual_rating'] >= RELEVANCE_THRESHOLD
        })

recommendations_df = pd.DataFrame(recommendations_list)
recommendations_df.to_csv('/content/drive/MyDrive/Recommendation/requirements/topn_recommendations.csv', index=False)
print("✓ Saved: topn_recommendations.csv")

# Save per-user metrics
user_metrics_list = []
for user_id, metrics in user_metrics.items():
    user_metrics_list.append({
        'userId': user_id,
        'precision': metrics['precision'],
        'recall': metrics['recall'],
        'ndcg': metrics['ndcg'],
        'num_ratings': metrics['count']
    })

user_metrics_df = pd.DataFrame(user_metrics_list)
user_metrics_df.to_csv('/content/drive/MyDrive/Recommendation/requirements/user_metrics.csv', index=False)
print("✓ Saved: user_metrics.csv")

# Display sample recommendations
print("\n" + "="*60)
print("SAMPLE TOP-10 RECOMMENDATIONS (First 3 Users)")
print("="*60)

for i, (user_id, recs) in enumerate(list(user_recommendations.items())[:3]):
    print(f"\nUser {user_id}:")
    print(f"  Metrics - P@{N_RECOMMENDATIONS}: {user_metrics[user_id]['precision']:.3f}, "
          f"R@{N_RECOMMENDATIONS}: {user_metrics[user_id]['recall']:.3f}, "
          f"NDCG@{N_RECOMMENDATIONS}: {user_metrics[user_id]['ndcg']:.3f}")
    print(f"  {'Rank':<6} {'MovieID':<10} {'Predicted':<10} {'Actual':<10} {'Relevant'}")
    print("  " + "-"*50)
    for rank, rec in enumerate(recs, 1):
        is_rel = "✓" if rec['actual_rating'] >= RELEVANCE_THRESHOLD else "✗"
        print(f"  {rank:<6} {rec['movieId']:<10} {rec['predicted_rating']:<10.3f} "
              f"{rec['actual_rating']:<10.1f} {is_rel}")

print("\n" + "="*60)
print("✓ COMPLETE!")
print("="*60)
print(f"Total runtime: {time.time() - start_time:.2f}s")